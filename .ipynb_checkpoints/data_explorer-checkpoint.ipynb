{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e331a7fb",
   "metadata": {},
   "source": [
    "# ideas\n",
    "- word count per doc\n",
    "- word repetition\n",
    "- phrase repition\n",
    "- sentiment\n",
    "- rhyme\n",
    "- modeling of certain topics (eg love)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f668466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "568cb7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALink</th>\n",
       "      <th>SName</th>\n",
       "      <th>SLink</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>language</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Songs</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Careless Whisper</td>\n",
       "      <td>/ivete-sangalo/careless-whisper.html</td>\n",
       "      <td>I feel so unsure\\nAs I take your hand and lead...</td>\n",
       "      <td>en</td>\n",
       "      <td>Ivete Sangalo</td>\n",
       "      <td>Pop; Axé; Romântico</td>\n",
       "      <td>313.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Romântico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ALink             SName                                 SLink  \\\n",
       "0  /ivete-sangalo/  Careless Whisper  /ivete-sangalo/careless-whisper.html   \n",
       "\n",
       "                                               Lyric language         Artist  \\\n",
       "0  I feel so unsure\\nAs I take your hand and lead...       en  Ivete Sangalo   \n",
       "\n",
       "                Genres  Songs  Popularity      genre  \n",
       "0  Pop; Axé; Romântico  313.0         4.4  Romântico  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_genre = pd.read_csv(\"data/selected_genres.csv\")\n",
    "df_genre.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236de15d",
   "metadata": {},
   "source": [
    "### Generate dataframe for each selected genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f69f5b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace name of Romantico to avoid future problems\n",
    "# Must be adjusted if there are any other special symbols, \n",
    "# a general processing function is likely not neccessary\n",
    "df_genre[\"genre\"] = df_genre.genre.str.replace(\"Romântico\",\"Romantico\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6350017",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dict = {}\n",
    "for genre in df_genre.genre.unique():\n",
    "    genre_dict[genre] = df_genre.loc[df_genre.genre==genre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90e73d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing the following genres:['Romantico' 'Rap' 'Gospel/Religioso' 'Country' 'Heavy Metal' 'Hardcore']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Analysing the following genres:{df_genre.genre.unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21d5415",
   "metadata": {},
   "source": [
    "# Preprocess text\n",
    "Some basic preprocessing\n",
    "TODO: expand this to remove more punctation and process phrases\n",
    "(e.g. I'm..) right now there are still some symbols left and counted as tokens..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0962202b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/thenextmz/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/thenextmz/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/thenextmz/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk, string, re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import words\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('words')\n",
    "\n",
    "extra_words_to_remove = [\"im\", \"verse\", \"™\", \"lyric\", \"chorus\"]\n",
    "def process_lyrics(df):\n",
    "    tknzr = TweetTokenizer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = nltk.corpus.stopwords.words('english')\n",
    "    punctuation = list(string.punctuation)\n",
    "    remove = set(stop_words + punctuation)\n",
    "    regex = \"[-!\\\"#$€%&'()*+,./:;<=>?@[\\]^_`{|}~”1234567890]\"\n",
    "    lyrics_tokenized = list(df.Lyric.apply(lambda x: [re.sub(regex, \"\", lemmatizer.lemmatize(i)) for i in tknzr.tokenize(x.lower()) if i not in remove and len(i) > 1]))\n",
    "    for j, text in enumerate(lyrics_tokenized):\n",
    "        lyrics_tokenized[j] = list(filter(None, text))\n",
    "        \n",
    "    for j, text in enumerate(lyrics_tokenized): \n",
    "        for i, word in enumerate(text):\n",
    "            if word in extra_words_to_remove or len(word) < 2:\n",
    "                text.pop(i)        \n",
    "    return lyrics_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8283c970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Romantico\n"
     ]
    }
   ],
   "source": [
    "processed_lyrics = {}\n",
    "\n",
    "for genre in genre_dict:   \n",
    "    df_genre = genre_dict[genre]\n",
    "    print(f\"Processing {genre}\")\n",
    "    pl = process_lyrics(df_genre)\n",
    "    processed_lyrics[genre] = pl   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbdf222",
   "metadata": {},
   "source": [
    "# Print data stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c999d9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in genre_dict:\n",
    "    n_songs =  len(processed_lyrics[genre])\n",
    "    songs = processed_lyrics[genre]\n",
    "    total_words = 0\n",
    "    unique_words = 0\n",
    "    for song in songs:\n",
    "        unique_words+= len(np.unique(song))\n",
    "        total_words+=len(song)\n",
    "    avg_song_len = total_words/len(songs)\n",
    "    avg_uq_words = unique_words/len(songs)\n",
    "    print(f\"Genre:{genre}\")\n",
    "    print(f\"Number of songs:{n_songs}\")\n",
    "    print(f\"Average number of words per song:{round(avg_song_len)}\")\n",
    "    print(f\"Average number of UNIQUE words per song:{round(avg_uq_words)}\")\n",
    "    print(f\"Unique words: {round(100*(avg_uq_words/avg_song_len))}%\")\n",
    "    print(\"------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214be1d0",
   "metadata": {},
   "source": [
    "# Term frequencies and n-grams\n",
    "- term frequency calculated with freqdist\n",
    "- tf_per_genre = all terms of one genre ranked (independent of song)\n",
    "- tf_per_genre_per_song = contains tf for each song\n",
    "- TODO: get n-grams - sequences of words (eg. 4-grams \"We will rock you\"), could be nice to show how much repetion a song has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d73790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(df,lyrics_tokenized,token_Freq):  \n",
    "    song_names = list(df.SName.values)\n",
    "    tf_per_song = {}\n",
    "    \n",
    "    for idx,val in enumerate(song_names):\n",
    "        sname = song_names[idx]\n",
    "        text = lyrics_tokenized[idx]\n",
    "        token_freq.update(text)\n",
    "        tf_per_song[sname]= nltk.FreqDist(text) \n",
    "    return tf_per_song\n",
    "\n",
    "tf_per_genre = {}\n",
    "tf_per_genre_per_song = {}\n",
    "\n",
    "tf_genre_dict = {}\n",
    "count = 0\n",
    "for genre in processed_lyrics:\n",
    "    token_freq = nltk.FreqDist()\n",
    "    pl = processed_lyrics[genre]\n",
    "    df = genre_dict[genre]\n",
    "    print(f\"Calculating tf for {genre}\")\n",
    "    tf_per_genre_per_song[genre] = tf(df,pl,token_freq)\n",
    "    tf_per_genre[genre]= token_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f157104",
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in tf_per_genre:\n",
    "    freq = tf_per_genre[genre]\n",
    "    n = 10\n",
    "    print(f\"Top {n} terms for {genre}:\")\n",
    "    print(dict(freq.most_common(10)))\n",
    "    print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7065e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_grams(df, lyrics_tokenized, window_size):\n",
    "    song_names = list(df.SName.values)\n",
    "    n_grams_per_song = {}\n",
    "    for idx,val in enumerate(song_names):\n",
    "        n_grams_arr = []\n",
    "        text = lyrics_tokenized[idx]\n",
    "        for i, word in enumerate(text):\n",
    "            for j in range(1, window_size + 1):\n",
    "                if(i + j <= len(text) - 1):\n",
    "                    n_grams_arr.append((word, text[i + j]))     \n",
    "        n_grams_per_song[idx] = n_grams_arr\n",
    "    return n_grams_per_song\n",
    "\n",
    "n_gram_per_genre_per_song = {}\n",
    "window_size = 1\n",
    "for genre in processed_lyrics:\n",
    "    pl = processed_lyrics[genre]\n",
    "    df = genre_dict[genre]\n",
    "    print(f\"Calculating n_grams for {genre}\")\n",
    "    n_gram_per_genre_per_song[genre] = n_grams(df, pl, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a73739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "num_most = 10\n",
    "def get_most_common_ngrams(n_grams_one_genre):\n",
    "    all_n_grams_per_genre = []\n",
    "    for idx in n_grams_one_genre:\n",
    "        for n_gram in n_grams_one_genre[idx]:\n",
    "              all_n_grams_per_genre.append(n_gram)\n",
    "    return(Counter(all_n_grams_per_genre))       \n",
    "\n",
    "most_common_per_genre = {}\n",
    "for genre in n_gram_per_genre_per_song:\n",
    "    most_common_per_genre[genre] = get_most_common_ngrams(n_gram_per_genre_per_song[genre])\n",
    "    print(f\"The {num_most} most common phrases for {genre} are:\")\n",
    "    print(most_common_per_genre[genre].most_common(num_most))\n",
    "    print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ac3842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_repetition_ngrams(phrases):\n",
    "    unique = []\n",
    "    for i, phrase in enumerate(phrases):\n",
    "        if phrase[0] != phrase[1]:\n",
    "            unique.append(phrase)\n",
    "    return unique\n",
    "\n",
    "no_repetition = {}\n",
    "for genre in most_common_per_genre:\n",
    "    no_repetition[genre] = no_repetition_ngrams(most_common_per_genre[genre])\n",
    "    print(f\"Percentage of n_grams without repetition for genre {genre} is {round(100*(len(no_repetition[genre])/len(most_common_per_genre[genre])), 4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf59c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_arr = []\n",
    "for i, genre in enumerate(n_gram_per_genre_per_song):\n",
    "        for j, genre2 in enumerate(most_common_per_genre):\n",
    "            if genre != genre2 and j >= i:\n",
    "                overlap = len(set(most_common_per_genre[genre])&set(most_common_per_genre[genre2])) / float(len(set(most_common_per_genre[genre]) | set(most_common_per_genre[genre2]))) * 100\n",
    "                overlap_arr.append({\"genre_pair\": (genre,genre2), \"overlap\": overlap})\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca920200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_overlap = sorted(overlap_arr, key=operator.itemgetter('overlap'), reverse=True)\n",
    "gp = \"genre_pair\"\n",
    "olp = \"overlap\"\n",
    "for elem in sorted_overlap:\n",
    "    print(f\"N_gram overlap of {elem[gp][0]} & {elem[gp][1]} = {round(elem[olp])}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279e8777",
   "metadata": {},
   "source": [
    "# Word Cloud\n",
    "- TODO empty plots, run this again with savefig before show (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34c84b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for genre in tf_per_genre:\n",
    "    freq = tf_per_genre[genre]\n",
    "    freq_dict = dict(freq.most_common(75))\n",
    "    wordcloud = WordCloud().generate_from_frequencies(freq_dict)\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")    \n",
    "    fname = genre\n",
    "    if \"/\" in fname:\n",
    "        fname = fname.replace(\"/\",\"_\")\n",
    "    plt.savefig(f\"plots/{fname}_wordcloud.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494e7a5d",
   "metadata": {},
   "source": [
    "# Sentiment of genres\n",
    "- Basic implementation of sentiment analysis\n",
    "- Sentences need to be split because else they will be too long for the model\n",
    "- Splitting can be improved, preprocessing steps applied etc.\n",
    "- For now only down on small amounts of data (because the model is really slow), should be plotted and compares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8d1a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!pip install -q transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "model = pipeline(\"sentiment-analysis\",model=\"siebert/sentiment-roberta-large-english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2c249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(genre,n_songs=20):\n",
    "    sentiment_scores = {\n",
    "    \"NEGATIVE\":{\"count\":0,\"score\":0},\n",
    "    #\"NEU\":{\"count\":0,\"score\":0},\n",
    "    \"POSITIVE\":{\"count\":0,\"score\":0}\n",
    "    }\n",
    "    nr_sentences = 0\n",
    "    songs = genre_dict[genre].Lyric.values[0:n_songs]\n",
    "    for song in songs:\n",
    "        sentences = song.split(\"\\n\")\n",
    "        #sentences = song\n",
    "        nr_sentences+=len(sentences)\n",
    "        sent = model(sentences)    \n",
    "        for s in sent:\n",
    "            label = s[\"label\"]\n",
    "            score =s[\"score\"]\n",
    "            sentiment_scores[label][\"count\"]+=1\n",
    "            sentiment_scores[label][\"score\"]+=score\n",
    "    for label in sentiment_scores:\n",
    "        if sentiment_scores[label][\"count\"]!=0:\n",
    "            sentiment_scores[label][\"score\"]/=sentiment_scores[label][\"count\"]\n",
    "            sentiment_scores[label][\"count\"]/=nr_sentences\n",
    "    return sentiment_scores\n",
    "\n",
    "sentiment_dict = {}\n",
    "for genre in genre_dict:\n",
    "    print(f\"getting sentiment for genre:{genre}\")\n",
    "    sentiment_dict[genre]= get_sentiment(genre,20)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9341fb",
   "metadata": {},
   "source": [
    "### plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6b6517",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals= []\n",
    "labels_genre = []\n",
    "pos = []\n",
    "neg = []\n",
    "for genre in sentiment_dict:\n",
    "    senti = sentiment_dict[genre]\n",
    "    labels_genre.append(genre)\n",
    "    labels_senti= [\"POSITIVE\",\"NEGATIVE\"]\n",
    "    vals.append([senti[\"POSITIVE\"][\"count\"],senti[\"NEGATIVE\"][\"count\"]])\n",
    "    pos.append(senti[\"POSITIVE\"][\"count\"])\n",
    "    neg.append(senti[\"NEGATIVE\"][\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bca848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# set width of bars\n",
    "barWidth = 0.25\n",
    " \n",
    "# set heights of bars\n",
    "\n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(pos))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "\n",
    "# Make the plot\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(r1, pos, color='#30C23D', width=barWidth, edgecolor='white', label='POSITIVE')\n",
    "plt.bar(r2, neg, color='#3E4676', width=barWidth, edgecolor='white', label='NEGATIVE')\n",
    "\n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('Genre', fontweight='bold')\n",
    "plt.xticks([r + barWidth for r in range(len(labels_genre))], labels_genre)\n",
    " \n",
    "# Create legend & Show graphic\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(\"plots/sentiment.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ace9c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment_dict[\"Romantico\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b643a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# genre_dict[\"Romantico\"].Lyric.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49d6d28",
   "metadata": {},
   "source": [
    "# Rhyme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4152f0c",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "- TODO: Cluster songs too see overlap (eg are hardcore and rock closer together than hardcore and Romantico etc.)\n",
    "- probably needs more preprocessing too (either embeddings, onehot encoding of words, stop word removal etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f53437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "\n",
    "fig = plt.figure(figsize=(12,10))\n",
    "text = np.empty([0,], dtype=str)\n",
    "target = np.empty([0,], dtype=str)\n",
    "\n",
    "lyrics_amount = 50\n",
    "count = 0\n",
    "for genre in processed_lyrics:\n",
    "    df = genre_dict[genre].head(lyrics_amount)[[\"genre\",\"Lyric\"]]\n",
    "    text = np.append(text, df.Lyric.values)\n",
    "    target = np.append(target, df.genre.values)\n",
    "    target[target == genre] = count\n",
    "    count += 1\n",
    "\n",
    "text_vec = TfidfVectorizer(lowercase=True, stop_words='english', analyzer='word')\n",
    "text_vec.fit(text)\n",
    "features = text_vec.transform(text)\n",
    "\n",
    "tsne_2d = TSNE(n_components=2, perplexity=30, random_state=0)\n",
    "\n",
    "features_2d = pd.DataFrame(tsne_2d.fit_transform(features.toarray()))\n",
    "cluster = KMeans(init=\"k-means++\",n_clusters=6, n_init=100, max_iter = 300, random_state=0)\n",
    "cluster.fit(features_2d)\n",
    "centroid = cluster.cluster_centers_\n",
    "\n",
    "labels = np.zeros_like(cluster.predict(features_2d))\n",
    "for i in range(6):\n",
    "    mask = (cluster.predict(features_2d) == i)\n",
    "    labels[mask] = mode(target[mask])[0]\n",
    "interval_start = 0\n",
    "print(f\"K-means clustering\")\n",
    "print(f\"---------------------------------\")\n",
    "for genre in processed_lyrics:\n",
    "    target_interval = target[interval_start:interval_start+lyrics_amount]\n",
    "    label_interval = labels[interval_start:interval_start+lyrics_amount]\n",
    "    print(genre)\n",
    "    print(f\"Accuracy: {(target_interval==label_interval).sum()/lyrics_amount}\")\n",
    "    print(f\"---------------------------------\")\n",
    "    interval_start += lyrics_amount\n",
    "plt.scatter(features_2d[0], features_2d[1], c=cluster.labels_)\n",
    "plt.scatter(centroid[:,0], centroid[:,1], c='red', s=50)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ee2676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification model\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.svm import SVC\n",
    "from numpy import mean\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "text = np.empty([0,], dtype=str)\n",
    "target = np.empty([0,], dtype=str)\n",
    "\n",
    "seed = 1234\n",
    "lyrics_amount = 500\n",
    "\n",
    "for genre in processed_lyrics:\n",
    "    \n",
    "    df = genre_dict[genre][[\"genre\",\"Lyric\"]].sample(n=lyrics_amount, random_state=seed)\n",
    "    text = np.append(text, df.Lyric.values)\n",
    "    target = np.append(target, df.genre.values)\n",
    "\n",
    "def clean_text(dataset):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    cleaned_dataset = []\n",
    "    punctuation = string.punctuation\n",
    "    #add numbers to punctuation\n",
    "    punctuation = punctuation + '0123456789'\n",
    "    word_length_cut = 1\n",
    "    for text in dataset:\n",
    "        text = text.lower()\n",
    "        for element in punctuation:\n",
    "            text = text.replace(element, '')\n",
    "        text = text.replace('verse', '')\n",
    "        words = word_tokenize(text)\n",
    "        filtered_words = [word for word in words if not word in stop_words]\n",
    "        cleaned_words = [stemmer.stem(word) for word in filtered_words if not word in punctuation]\n",
    "        cleaned_words = [word for word in cleaned_words if len(word) > word_length_cut]\n",
    "        cleaned_dataset.append(cleaned_words)\n",
    "    return cleaned_dataset\n",
    "cleaned_text= clean_text(text)\n",
    "\n",
    "w2v_size = 100\n",
    "\n",
    "w2v_model = Word2Vec(cleaned_text, vector_size=w2v_size, window=3, min_count=1, sg=0, epochs=100)\n",
    "\n",
    "single_words = set(w2v_model.wv.index_to_key)\n",
    "w2v = [[w2v_model.wv[index] for index in word if index in single_words] for word in cleaned_text]\n",
    "\n",
    "w2v_average = []\n",
    "for vector in w2v:\n",
    "    w2v_average.append(mean(vector, axis=0))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(w2v_average, target, test_size=0.20, shuffle=True, random_state=seed)\n",
    "\n",
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "print(f'Model accuracy score: {accuracy_score(y_test, y_predict)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "d2af68a4b51633f13995ebfae92a57b161ed6e58c9d8595f65fa30edeb049295"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
